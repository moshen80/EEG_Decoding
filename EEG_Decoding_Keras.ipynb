{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9aef4822-1ade-4528-b9f1-bb00322f6e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow import one_hot\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2462bce3-a457-483e-95bb-9f584b948c4e",
   "metadata": {},
   "source": [
    "### Reading the Training and Test data\n",
    "The dimention of the data shall be #Trials x #Contatcts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33306bae-b324-41a9-bca4-3742e49c9de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "EEG_data = \"Data/EEG\"\n",
    "Label_data = \"Data/Labels\"\n",
    "# Reading Training EEG Data and their labels\n",
    "train_data = pd.read_csv(os.path.join(EEG_data,'training_set.csv'), header=None)\n",
    "train_data = np.array(train_data).astype('float32')\n",
    "\n",
    "# Reading Test EEG Data and their labels\n",
    "test_data = pd.read_csv(os.path.join(EEG_data, 'test_set.csv'), header=None)\n",
    "test_data = np.array(test_data).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "84e481fc-de14-407f-83c2-e5eef2e943e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = pd.read_csv(os.path.join(Label_data , 'training_label.csv'), header=None)\n",
    "train_labels = np.array(train_labels).astype('int')\n",
    "test_labels = pd.read_csv(os.path.join(Label_data,'test_label.csv'), header=None)\n",
    "test_labels = np.array(test_labels).astype('int')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc1d34c-8c07-4c88-92b2-6e4a0e2a970f",
   "metadata": {},
   "source": [
    "Both Training and Test Data have 64x64 feature size which come from 64-contacts EEG signal and 64 sample in time \\\n",
    "which will be used for classification purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5c1e4b63-52d0-4f8c-994f-cf6fc029f3ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data Size: (76356, 4096)\n",
      "Test Data Size: (8484, 4096)\n"
     ]
    }
   ],
   "source": [
    "print('Train Data Size: {}'.format(train_data.shape))\n",
    "print('Test Data Size: {}'.format(test_data.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "cf361e97-714d-442c-aef5-378cef422469",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot representation of trian and test labels\n",
    "train_labels = tf.one_hot(indices=train_labels, depth=4)\n",
    "train_labels = tf.squeeze(train_labels)\n",
    "test_labels = tf.one_hot(indices=test_labels, depth=4)\n",
    "test_labels = tf.squeeze(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "091b7e5e-e965-4114-b0d6-7b2d86acee9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(76356, 4)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "e55de480-3e5b-424e-9832-73b3b3a4ae34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Hyper-parameters\n",
    "n_contacts   = 64      # The number of EEG contacts at each time point\n",
    "n_time  = 64      # number of EEG time points to feed to the model\n",
    "n_neurons_lstm = 256     # number of neurons in the LSTM layn_er\n",
    "n_attention = 8  # The number of neurons in attention layer\n",
    "\n",
    "n_class   = 4     # The number of classification classes\n",
    "n_neurons_FC  = 64    # The number of hidden units in the FC layer\n",
    "num_epoch = 300   # The number of Epochs that the Model run\n",
    "keep_rate = 0.75  # Keep rate of the Dropout\n",
    "\n",
    "lr = tf.constant(1e-4, dtype=tf.float32)  # Learning rate\n",
    "lr_decay_epoch = 50    # Every (50) epochs, the learning rate decays\n",
    "lr_decay       = 0.50  # Learning rate Decay by (50%)\n",
    "\n",
    "batch_size = 128\n",
    "n_batch = train_data.shape[0] // batch_size\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "332c33de-ad4b-4d3a-ae23-081c32d1e078",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.reshape(train_data, [-1, max_time, n_input])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "dd9c06de-26ad-46a4-b9f8-da5e9acac212",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "391b0137-c5c3-4c7f-b69d-76c2bcd941bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class attention(Layer):\n",
    "    def __init__(self, return_sequences=True):\n",
    "        self.return_sequences = return_sequences\n",
    "        super(attention,self).__init__()\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        \n",
    "        self.W=self.add_weight(name=\"att_weight\", shape=(input_shape[-1],1),\n",
    "                               initializer=\"normal\")\n",
    "        self.b=self.add_weight(name=\"att_bias\", shape=(input_shape[1],1),\n",
    "                               initializer=\"zeros\")\n",
    "        super(attention,self).build(input_shape)\n",
    "        \n",
    "    def call(self, x):\n",
    "        \n",
    "        e = K.tanh(K.dot(x,self.W)+self.b)\n",
    "        a = K.softmax(e, axis=1)\n",
    "        output = x*a\n",
    "        \n",
    "        if self.return_sequences:\n",
    "            return output\n",
    "        \n",
    "        return K.sum(output, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "4e6b601b-74e9-4018-8ae6-d9199342013b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bidirectional_1 (Bidirection (None, 64, 512)           657408    \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 64, 64)            147712    \n",
      "_________________________________________________________________\n",
      "attention_1 (attention)      (None, 64, 64)            128       \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 64, 64)            4160      \n",
      "_________________________________________________________________\n",
      "time_distributed_2 (TimeDist (None, 64, 4)             260       \n",
      "=================================================================\n",
      "Total params: 809,668\n",
      "Trainable params: 809,668\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Bidirectional(LSTM(lstm1_size, return_sequences=True,activation='tanh',recurrent_dropout=dropout_prob),\n",
    "                        input_shape=(X.shape[1],X.shape[2])))\n",
    "model.add(LSTM(lstm2_size, return_sequences=True,activation='tanh',recurrent_dropout=dropout_prob,\n",
    "                        input_shape=(X.shape[1],X.shape[2])))\n",
    "\n",
    "model.add(attention(return_sequences=True)) # receive 3D and output 3D\n",
    "model.add(TimeDistributed(Dense(n_neurons_FC,activation='softmax')))\n",
    "model.add(TimeDistributed(Dense(n_neurons_SM,activation='softmax')))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "dfd9ecc4-5d79-4289-af49-a9e4a30ab729",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216344ab-f544-41eb-a3c9-f8086057992c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59711c0f-1b34-449c-879c-bcc9fb2324ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ca9ac0-3197-4d7b-b7f2-4f8345f33849",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f5954e29-5d23-4de3-a864-a5286e7072b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "545e7346-75ce-451f-bc9f-d82e9b657d8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4574920e-ea3d-4591-b410-12de18f7ccca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
