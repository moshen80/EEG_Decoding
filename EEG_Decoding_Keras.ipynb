{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9aef4822-1ade-4528-b9f1-bb00322f6e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedShuffleSplit,train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow import one_hot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2462bce3-a457-483e-95bb-9f584b948c4e",
   "metadata": {},
   "source": [
    "### Reading the Training and Test data\n",
    "The dimention of the data shall be #Trials x #Contatcts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33306bae-b324-41a9-bca4-3742e49c9de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "EEG_data = \"Data/EEG\"\n",
    "Label_data = \"Data/Labels\"\n",
    "# Reading Training EEG Data and their labels\n",
    "train_data = pd.read_csv(os.path.join(EEG_data,'training_set.csv'), header=None)\n",
    "train_data = np.array(train_data).astype('float32')\n",
    "\n",
    "# Reading Test EEG Data and their labels\n",
    "test_data = pd.read_csv(os.path.join(EEG_data, 'test_set.csv'), header=None)\n",
    "test_data = np.array(test_data).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84e481fc-de14-407f-83c2-e5eef2e943e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = pd.read_csv(os.path.join(Label_data , 'training_label.csv'), header=None)\n",
    "train_labels = np.array(train_labels).astype('int')\n",
    "test_labels = pd.read_csv(os.path.join(Label_data,'test_label.csv'), header=None)\n",
    "test_labels = np.array(test_labels).astype('int')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc1d34c-8c07-4c88-92b2-6e4a0e2a970f",
   "metadata": {},
   "source": [
    "Both Training and Test Data have 64x64 feature size which come from 64-contacts EEG signal and 64 sample in time \\\n",
    "which will be used for classification purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c1e4b63-52d0-4f8c-994f-cf6fc029f3ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data Size: (76356, 4096)\n",
      "Test Data Size: (8484, 4096)\n"
     ]
    }
   ],
   "source": [
    "print('Train Data Size: {}'.format(train_data.shape))\n",
    "print('Test Data Size: {}'.format(test_data.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf361e97-714d-442c-aef5-378cef422469",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot representation of trian and test labels\n",
    "train_labels = tf.one_hot(indices=train_labels, depth=4)\n",
    "train_labels = tf.squeeze(train_labels)\n",
    "test_labels = tf.one_hot(indices=test_labels, depth=4)\n",
    "test_labels = tf.squeeze(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091b7e5e-e965-4114-b0d6-7b2d86acee9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e55de480-3e5b-424e-9832-73b3b3a4ae34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Hyper-parameters\n",
    "n_contacts   = 64      # The number of EEG contacts at each time point\n",
    "n_time  = 64      # number of EEG time points to feed to the model\n",
    "n_neurons_lstm_1 = 128     # number of neurons in the LSTM layer\n",
    "n_neurons_lstm_2 = 64     # number of neurons in the LSTM layer\n",
    "n_attention = 8  # The number of neurons in attention layer\n",
    "\n",
    "n_class   = 4     # The number of classification classes\n",
    "n_neurons_FC  = 64    # The number of hidden units in the FC layer\n",
    "n_neurons_SM  = n_class    # The number of hidden units in the SoftMax layer\n",
    "num_epoch = 300   # The number of Epochs that the Model run\n",
    "keep_rate = 0.75  # Keep rate of the Dropout\n",
    "dropout_prob = 1-keep_rate\n",
    "n_batch = 128\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "332c33de-ad4b-4d3a-ae23-081c32d1e078",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.reshape(train_data, [-1, n_time, n_contacts])\n",
    "y = train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "391b0137-c5c3-4c7f-b69d-76c2bcd941bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class attention(Layer):\n",
    "    def __init__(self, return_sequences=True):\n",
    "        self.return_sequences = return_sequences\n",
    "        super(attention,self).__init__()\n",
    "    def build(self, input_shape):\n",
    "        self.W=self.add_weight(name=\"att_weight\", shape=(input_shape[-1],1),\n",
    "                               initializer=\"normal\")\n",
    "        self.b=self.add_weight(name=\"att_bias\", shape=(input_shape[1],1),\n",
    "                               initializer=\"zeros\")\n",
    "        super(attention,self).build(input_shape)\n",
    "    def call(self, x):\n",
    "        e = K.tanh(K.dot(x,self.W)+self.b)\n",
    "        a = K.softmax(e, axis=1)\n",
    "        output = x*a\n",
    "        \n",
    "        if self.return_sequences:\n",
    "            return output\n",
    "        \n",
    "        return K.sum(output, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4e6b601b-74e9-4018-8ae6-d9199342013b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bidirectional (Bidirectional (None, 64, 256)           197632    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 64, 64)            82176     \n",
      "_________________________________________________________________\n",
      "attention (attention)        (None, 64, 64)            128       \n",
      "_________________________________________________________________\n",
      "time_distributed (TimeDistri (None, 64, 64)            4160      \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 64, 4)             260       \n",
      "=================================================================\n",
      "Total params: 284,356\n",
      "Trainable params: 284,356\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Bidirectional(LSTM(n_neurons_lstm_1, return_sequences=True,activation='tanh',recurrent_dropout=dropout_prob),\n",
    "                        input_shape=(X.shape[1],X.shape[2])))\n",
    "model.add(LSTM(n_neurons_lstm_2, return_sequences=True,activation='tanh',recurrent_dropout=dropout_prob,\n",
    "                        input_shape=(X.shape[1],X.shape[2])))\n",
    "\n",
    "model.add(attention(return_sequences=True)) # receive 3D and output 3D\n",
    "model.add(TimeDistributed(Dense(n_neurons_FC,activation='relu')))\n",
    "model.add(TimeDistributed(Dense(n_neurons_SM,activation='softmax')))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b42e55-5679-4382-a2b6-24ace74313c8",
   "metadata": {},
   "source": [
    "### Training and Testing the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "dfd9ecc4-5d79-4289-af49-a9e4a30ab729",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = {}\n",
    "cv = 10\n",
    "for j in range(cv): \n",
    "    history[j] = []\n",
    "accuracy = np.zeros((y.shape[1],cv))\n",
    "SSS = StratifiedShuffleSplit(n_splits=cv, test_size=0.4)\n",
    "j=0\n",
    "for train_index, test_index in SSS.split(X, y):\n",
    "    X_train, X_test = X[train_index,:,:], X[test_index,:,:]\n",
    "    y_train, y_test = y[train_index,:], y[test_index,:]\n",
    "    history[j] = model.fit(X_train, one_hot(y_train,depth=3), epochs=n_epoch, batch_size=n_batch,validation_split=0.2 ,verbose=1)\n",
    "    result = model.predict(X_test, batch_size=n_batch, verbose=0)\n",
    "    y_classes = tf.argmax(result,2)\n",
    "    for i in range(y_test.shape[1]):\n",
    "        accuracy[i,j] =  accuracy_score(y_test[:,i], y_classes[:,i])\n",
    "    j = j+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216344ab-f544-41eb-a3c9-f8086057992c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59711c0f-1b34-449c-879c-bcc9fb2324ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ca9ac0-3197-4d7b-b7f2-4f8345f33849",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f5954e29-5d23-4de3-a864-a5286e7072b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "545e7346-75ce-451f-bc9f-d82e9b657d8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4574920e-ea3d-4591-b410-12de18f7ccca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
